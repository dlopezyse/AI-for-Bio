## Large Language Models in Biology ðŸ¤–

| Name | Description |
| :--- | :--- | 
| [BioBERT](https://github.com/dmis-lab/biobert) | BioBERT, a biomedical language representation model designed for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, question answering, etc. Please refer to the paper [BioBERT: a pre-trained biomedical language representation model for biomedical text mining](https://academic.oup.com/bioinformatics/article/36/4/1234/5566506) for more details.
| [BioGPT](https://github.com/microsoft/BioGPT) | The BioGPT model was proposed in [BioGPT: generative pre-trained transformer for biomedical text generation and mining](https://academic.oup.com/bib/article/23/6/bbac409/6713511?guestAccessKey=a66d9b5d-4f83-4017-bb52-405815c907b9&login=false) by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu. BioGPT is a domain-specific generative pre-trained Transformer language model for biomedical text generation and mining. BioGPT follows the Transformer language model backbone, and is pre-trained on 15M PubMed abstracts from scratch.
| [BioMedGPT](https://github.com/PharMolix/OpenBioMed?tab=readme-ov-file) | [BioMedGPT](https://arxiv.org/abs/2308.09442) is the first commercial-friendly multimodal biomedical foundation model jointly released by PharMolix and the Institute of AI Industry Research (AIR). It aligns the language of life (molecular structures and protein sequences) with human natural language, performing on par with human experts on biomedical QA benchmarks and demonstrating powerful performance in cross-modal molecule and protein question-answering tasks. 
